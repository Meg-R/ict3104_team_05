{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8DIWXFJULAp"
      },
      "source": [
        "# Team 5 ðŸ’£\n",
        "1. Maximus Lee\n",
        "2. Aloysius Woo\n",
        "3. Lim Huai Fu\n",
        "4. Tan Ai Xin\n",
        "5. Jin Zhenglong"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3lLyUO0UXTc"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-okH6K5sV4zP"
      },
      "outputs": [],
      "source": [
        "#@markdown Check type of GPU and VRAM available.\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpMOpVG_KhHb"
      },
      "source": [
        "### Install Environment\n",
        "Est Time: 8 mins\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "u9Vc4lO5K-H9"
      },
      "outputs": [],
      "source": [
        "# @title Python\n",
        "\n",
        "%cd /content\n",
        "!sudo apt-get install python3.8\n",
        "!sudo apt-get install python3.8-distutils\n",
        "\n",
        "!update-alternatives --install /usr/local/bin/python3 python3 /usr/bin/python3.8 2\n",
        "!apt-get update\n",
        "!apt install software-properties-common\n",
        "!sudo dpkg --remove --force-remove-reinstreq python3-pip python3-setuptools python3-wheel\n",
        "!apt-get install python3-pip\n",
        "!apt-get install libcairo2-dev\n",
        "!apt update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3WX-3yGTV_Sl"
      },
      "outputs": [],
      "source": [
        "#@title GitHub Repos\n",
        "\n",
        "# Empty default folder\n",
        "!find /content -mindepth 1 -delete\n",
        "\n",
        "# nice try\n",
        "!git clone https://github.com/maximus-lee-678/ict3104_team_05.git ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "L__YKZ9KK-mX"
      },
      "outputs": [],
      "source": [
        "#@title FollowYourPose/MMPose Folder Scaffolding\n",
        "\n",
        "# FollowYourPose\n",
        "%cd /content/FollowYourPose\n",
        "%mkdir /content/FollowYourPose/checkpoints\n",
        "\n",
        "# MMPose\n",
        "%cd /content/MMPose\n",
        "%mkdir video_input\n",
        "%mkdir video_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "a7DJu1U7WYW1"
      },
      "outputs": [],
      "source": [
        "#@title FollowYourPose/MMPose Libaries\n",
        "# https://github.com/open-mmlab/mmpose\n",
        "# https://blog.csdn.net/qq_21532607/article/details/130226728\n",
        "# https://colab.research.google.com/github/open-mmlab/mmpose/blob/master/demo/MMPose_Tutorial.ipynb\n",
        "\n",
        "%cd /content\n",
        "!python3.8 -m pip install -r other_files/requirements/requirements_colab.txt\n",
        "\n",
        "!python3.8 -m mim install mmengine\n",
        "!python3.8 -m mim install mmpose\n",
        "!python3.8 -m mim install \"mmcv>=2.0.0\"\n",
        "!python3.8 -m mim install \"mmdet>=3.0.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JtVLX0Lg68E"
      },
      "outputs": [],
      "source": [
        "#@title Others\n",
        "\n",
        "!pip install moviepy\n",
        "!apt-get install imagemagick\n",
        "!cat /etc/ImageMagick-6/policy.xml | sed 's/none/read,write/g'> /etc/ImageMagick-6/policy.xml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQxTxHN6WxMZ"
      },
      "source": [
        "### Mount Drive ðŸ—»\n",
        "\n",
        "1. Run the first cell to authenicate\n",
        "2. Click on the URL of the Failure in the output Failure(\"Error opening URL: ...\")\n",
        "3. Select the ICT3104 shared account\n",
        "4. Once successful, you can close the tab\n",
        "5. Run the next cell\n",
        "6. Done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "17pclDOQ9j6a"
      },
      "outputs": [],
      "source": [
        "# @title First Cell\n",
        "%cd -q /content\n",
        "!sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!sudo apt-get update -qq 2>&1 > /dev/null\n",
        "!sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "!google-drive-ocamlfuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XLNViD3y9oBS"
      },
      "outputs": [],
      "source": [
        "# @title Next Cell\n",
        "!sudo apt-get install -qq w3m # to act as web browser\n",
        "!xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
        "%cd -q /content\n",
        "!mkdir gdrive\n",
        "%cd -q gdrive\n",
        "!mkdir MyDrive\n",
        "%cd -q ..\n",
        "%cd -q ..\n",
        "!google-drive-ocamlfuse /content/gdrive/MyDrive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y12b9B4VLmqU"
      },
      "source": [
        "### Symbolic Linking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7uOweXNtEen"
      },
      "outputs": [],
      "source": [
        "# Root Directory\n",
        "ROOT_DIR_PATH = \"/content\"\n",
        "\n",
        "# Video\n",
        "VIDEO_DIR_PATH = f\"{ROOT_DIR_PATH}/video\"\n",
        "%mkdir {VIDEO_DIR_PATH}\n",
        "VIDEO_SKELETON_DIR_PATH = f\"{ROOT_DIR_PATH}/video/Skeleton\"\n",
        "%mkdir {VIDEO_SKELETON_DIR_PATH}\n",
        "\n",
        "# I/O Files\n",
        "TRAINING_CONTENT_DIR_PATH = f\"{ROOT_DIR_PATH}/training_content\"\n",
        "%mkdir {TRAINING_CONTENT_DIR_PATH}\n",
        "CUSTOM_MODEL_DIR_PATH = f\"{ROOT_DIR_PATH}/custom_model\"\n",
        "%mkdir {CUSTOM_MODEL_DIR_PATH}\n",
        "INFERENCE_OUTPUT_DIR_PATH = f\"{ROOT_DIR_PATH}/inference_output\"\n",
        "%mkdir {INFERENCE_OUTPUT_DIR_PATH}\n",
        "\n",
        "MMPOSE_DIR_PATH = f\"{ROOT_DIR_PATH}/MMPose\"\n",
        "FYP_DIR_PATH = f\"{ROOT_DIR_PATH}/FollowYourPose\"\n",
        "\n",
        "# FYP Config\n",
        "CONFIG_DIR_PATH = f\"{FYP_DIR_PATH}/configs\"\n",
        "%mkdir {CONFIG_DIR_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "939ytvIBS9Rn"
      },
      "outputs": [],
      "source": [
        "# symbolic link edition\n",
        "!ln -s /content/gdrive/MyDrive/ICT3104/video/* /content/video\n",
        "\n",
        "# copy edition\n",
        "# %cp -r /content/gdrive/MyDrive/ICT3104/video/* /content/video/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4YSBy4MJKx7"
      },
      "outputs": [],
      "source": [
        "# Checkpoints folder\n",
        "\n",
        "# symbolic link edition\n",
        "!ln -s /content/gdrive/MyDrive/ICT3104/checkpoints/* /content/FollowYourPose/checkpoints\n",
        "\n",
        "# copy edition\n",
        "# %cp -r /content/gdrive/MyDrive/ICT3104/checkpoints/* /content/FollowYourPose/checkpoints/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmKU0lBVYOKl"
      },
      "outputs": [],
      "source": [
        "# Charade Lookup Files\n",
        "%mkdir /content/charades_lookup/\n",
        "\n",
        "# symbolic link edition\n",
        "!ln -s /content/gdrive/MyDrive/ICT3104/charades_lookup/* /content/charades_lookup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoIkpghCv-4a"
      },
      "source": [
        "### Pre-setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oJx1Aeov2cU"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Check if the path is not already in sys.path before appending\n",
        "path_to_append = '/usr/local/lib/python3.8/dist-packages'\n",
        "if path_to_append not in sys.path:\n",
        "    sys.path.append(path_to_append)\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import datetime\n",
        "import time\n",
        "import subprocess\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "import yaml\n",
        "\n",
        "from ipywidgets import Dropdown, Output, Layout, widgets, Button, VBox, HBox\n",
        "from IPython.display import display, Markdown, HTML, Video, clear_output\n",
        "\n",
        "from moviepy.editor import VideoFileClip, clips_array, TextClip, CompositeVideoClip, ColorClip\n",
        "from moviepy.config import change_settings\n",
        "from PIL import Image, ImageDraw, ImageFont, ImageSequence\n",
        "\n",
        "change_settings({\"IMAGEMAGICK_BINARY\": \"/usr/bin/convert\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iamRWbAVylrD"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zoH5xX5yZSQ"
      },
      "outputs": [],
      "source": [
        "#@title Configuration Presets\n",
        "\n",
        "# Expected Configurations of a Inference yaml\n",
        "expected_inference_config = {\n",
        "  \"pretrained_model_path\": str,\n",
        "  \"output_dir\": str,\n",
        "  \"validation_data\": {\n",
        "      \"prompts\": list,\n",
        "      \"video_length\": int,\n",
        "      \"width\": int,\n",
        "      \"height\": int,\n",
        "      \"num_inference_steps\": int,\n",
        "      \"guidance_scale\": float,\n",
        "      \"use_inv_latent\": bool,\n",
        "      \"num_inv_steps\": int,\n",
        "      \"dataset_set\": str\n",
        "  },\n",
        "  \"train_batch_size\": int,\n",
        "  \"validation_steps\": int,\n",
        "  \"resume_from_checkpoint\": str,\n",
        "  \"seed\": int,\n",
        "  \"mixed_precision\": str,\n",
        "  \"gradient_checkpointing\": bool,\n",
        "  \"enable_xformers_memory_efficient_attention\": bool\n",
        "}\n",
        "\n",
        "# Expected Configurations of a Training yaml\n",
        "expected_training_config = {\n",
        "  \"pretrained_model_path\": str,\n",
        "  \"output_dir\": str,\n",
        "  \"train_data\": {\n",
        "    \"video_path\": str,\n",
        "    \"n_sample_frames\": int,\n",
        "    \"width\": int,\n",
        "    \"sample_frame_rate\": int\n",
        "  },\n",
        "  \"learning_rate\": float,\n",
        "  \"train_batch_size\": int,\n",
        "  \"max_train_steps\": int,\n",
        "  \"trainable_modules\": list,\n",
        "  \"seed\": int,\n",
        "  \"mixed_precision\": str,\n",
        "  \"use_8bit_adam\": bool,\n",
        "  \"gradient_checkpointing\": bool,\n",
        "  \"enable_xformers_memory_efficient_attention\": bool\n",
        "}\n",
        "\n",
        "# Define the options for boolean dropdown\n",
        "boolean_dropdown = [True, False]\n",
        "\n",
        "# Create layout\n",
        "configs_config_style = {'description_width': '150px'}\n",
        "configs_config_layout = widgets.Layout(width=\"500px\")\n",
        "configs_config_button_layout = widgets.Layout(margin='0px 0px 20px 354px')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKtJAlcqcgeB"
      },
      "outputs": [],
      "source": [
        "#@title Configuration Functions\n",
        "\n",
        "# Find all models and creates a list of the models' path in the directory\n",
        "def create_model_list():\n",
        "  model_options = [(\"Default\", f\"{FYP_DIR_PATH}/checkpoints/stable-diffusion-v1-4\")]\n",
        "  for model_name in os.listdir(CUSTOM_MODEL_DIR_PATH):\n",
        "    model_path = os.path.join(CUSTOM_MODEL_DIR_PATH, model_name)\n",
        "    if os.path.isdir(model_path):\n",
        "      model_options.append((model_name, f\"{CUSTOM_MODEL_DIR_PATH}/{model_name}\"))\n",
        "  return model_options\n",
        "\n",
        "def create_video_path_list():\n",
        "  video_path_options = [(\"None\", \"/content/training_content/\")]\n",
        "  for video_name in os.listdir(TRAINING_CONTENT_DIR_PATH):\n",
        "    video_path = os.path.join(TRAINING_CONTENT_DIR_PATH, video_name)\n",
        "    if os.path.isdir(video_path):\n",
        "      video_path_options.append((video_name, f\"{TRAINING_CONTENT_DIR_PATH}/{video_name}\"))\n",
        "  return video_path_options\n",
        "\n",
        "# Check if the yaml is in the correct structure for inference\n",
        "def compare_dict_structure(expected, yaml_config):\n",
        "  for key, value in expected.items():\n",
        "    if not isinstance(value, dict):\n",
        "      if key not in yaml_config or not isinstance(yaml_config[key], value): # Check if key exists and if data type matches\n",
        "        if key in yaml_config and isinstance(list(yaml_config[key]), value): # Special check for list because omegaconf sees it as a ListConfig\n",
        "          return True\n",
        "        return False\n",
        "    elif key in yaml_config: # If value is a dict recurse to its first non dict value\n",
        "      compare_dict_structure(value, yaml_config[key])\n",
        "  return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmXta0m2ioal"
      },
      "outputs": [],
      "source": [
        "#@title Post-Process Inference Functions\n",
        "\n",
        "def postprocess_gif(inf_path, prompt, size):\n",
        "\n",
        "  pose_path = f'{inf_path}/pose.gif'\n",
        "  gif_video_path = f'{inf_path}/raw/{prompt}.gif'\n",
        "  gif_output_path = f\"{inf_path}/processed/{prompt}.gif\"\n",
        "\n",
        "  # Load video\n",
        "  skeleton_video = VideoFileClip(pose_path)\n",
        "  gif_video = VideoFileClip(gif_video_path)\n",
        "\n",
        "  # Video editting\n",
        "  skeleton_video = skeleton_video.resize((size, size))\n",
        "  gif_video = gif_video.resize((size, size))\n",
        "\n",
        "  # Combine videos side by side\n",
        "  result = clips_array([[skeleton_video, gif_video]])\n",
        "\n",
        "  # Add captions\n",
        "  txt_clip = TextClip(prompt, font=\"Amiri-bold\", fontsize=30, color='white')\n",
        "  txt_clip = txt_clip.set_duration(result.duration)\n",
        "  txt_clip = txt_clip.set_position((\"center\", \"bottom\"))\n",
        "\n",
        "  # Create a black bar for captions\n",
        "  black_clip = ColorClip(size=(result.w, result.h + 40), color=(0, 0, 0), duration=result.duration)\n",
        "\n",
        "  # Combine clips with captions\n",
        "  gif_with_text = CompositeVideoClip([black_clip, txt_clip, result])\n",
        "\n",
        "  # Write the final GIF\n",
        "  gif_with_text.write_gif(gif_output_path, fps=10)\n",
        "\n",
        "def postprocess_mmpose(skeleton_path, video_length, output_dir):\n",
        "\n",
        "  # Get the video duration using ffprobe\n",
        "  duration = float(subprocess.check_output(['ffprobe', '-v', 'error', '-show_entries', 'format=duration', '-of', 'default=noprint_wrappers=1:nokey=1', skeleton_path]))\n",
        "\n",
        "  # Set your desired duration\n",
        "  desired_duration = video_length * 130 / 1000\n",
        "\n",
        "  # Calculate the speedup factor\n",
        "  speedup_factor = desired_duration / duration\n",
        "\n",
        "  # Run the FFmpeg command to adjust the video's duration\n",
        "  output_path = f'{output_dir}/pose.gif'\n",
        "  !ffmpeg -i $skeleton_path -vf \"setpts=$speedup_factor*PTS,fps=10\" $output_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg-ZSz5tvt3u"
      },
      "source": [
        "## Video Browsing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlVd08AVRZy6"
      },
      "outputs": [],
      "source": [
        "# @title Video Selection { display-mode: \"form\" }\n",
        "\n",
        "# Helper Functions\n",
        "def getFolderContent(folder_name):\n",
        "  subfolders = []\n",
        "  for content in os.listdir(VIDEO_DIR_PATH):\n",
        "        content_path = os.path.join(VIDEO_DIR_PATH, content)\n",
        "\n",
        "        # Check if it's a directory and not hidden\n",
        "        if os.path.isdir(content_path) and not content.startswith(\".\"):\n",
        "            subfolders.append(content)\n",
        "\n",
        "  return subfolders\n",
        "\n",
        "# Init\n",
        "video_dir_folders = os.listdir(VIDEO_DIR_PATH)\n",
        "video_dir_folder_content = getFolderContent(video_dir_folders)\n",
        "\n",
        "# Create layout\n",
        "layout_single_button = widgets.Layout(width='212px',margin='0px 0px 20px 90px')\n",
        "layout_double_button = widgets.Layout(width='104px')\n",
        "layout_hbox = widgets.Layout(margin='0px 0px 0px 88px')\n",
        "layout_output = widgets.Layout(margin='0px 0px 20px 0px', display='flex', align_items='flex-start')\n",
        "\n",
        "# Create widgets\n",
        "video_output_placeholder = widgets.Output(layout=layout_output)\n",
        "video_subdir_dropdown = widgets.Dropdown(options=video_dir_folder_content, description='Folder:', value=None, disabled=False)\n",
        "video_dropdown = widgets.Dropdown(options=[], description='Video:', disabled=True)\n",
        "video_display_button = widgets.Button(description=\"Display\", disabled=True, layout=layout_double_button)\n",
        "video_refresh_button = widgets.Button(description=\"Refresh\", disabled=False, layout=layout_double_button)\n",
        "video_mmpose_button = widgets.Button(description=\"MMPose\", disabled=True, layout=layout_double_button)\n",
        "video_fyp_button = widgets.Button(description=\"FYP\", disabled=True, layout=layout_double_button)\n",
        "\n",
        "video_hbox_1 = widgets.HBox([video_display_button, video_refresh_button], layout=layout_hbox)\n",
        "video_hbox_2 = widgets.HBox([video_mmpose_button, video_fyp_button], layout=layout_hbox)\n",
        "\n",
        "video_output_placeholder_content = HTML(\"\"\"\n",
        "  <div style=\"width: 512px; height: 512px; border-radius: 5%; background-color: black; margin: 0 auto; display: flex; justify-content: center; align-items: center;\">\n",
        "      <div style=\"width: 500px; height: 500px; border-radius: 5%; border: 2px solid white;\" />\n",
        "  </div>\n",
        "\"\"\")\n",
        "\n",
        "# Create listeners\n",
        "## Update video dropdown options based on the selected folder\n",
        "def video_subdir_select(change):\n",
        "    selected_video_folder = video_subdir_dropdown.value\n",
        "\n",
        "    if selected_video_folder != None:\n",
        "      selected_VIDEO_DIR_PATH = f\"{VIDEO_DIR_PATH}/{selected_video_folder}\"\n",
        "      selected_video_dir_content = [file for file in os.listdir(selected_VIDEO_DIR_PATH) if file.endswith('.mp4')]\n",
        "    else:\n",
        "      selected_video_dir_content = []\n",
        "\n",
        "    video_dropdown.options = selected_video_dir_content\n",
        "    if not selected_video_dir_content:\n",
        "        video_dropdown.disabled = False\n",
        "        video_dropdown.value = None\n",
        "    else:\n",
        "        video_dropdown.disabled = False\n",
        "\n",
        "## Display the selected video\n",
        "def display_selected_video(change):\n",
        "    selected_video = video_dropdown.value\n",
        "    selected_video_folder = video_subdir_dropdown.value\n",
        "\n",
        "    if selected_video:\n",
        "        video_path = f\"{VIDEO_DIR_PATH}/{selected_video_folder}/{selected_video}\"\n",
        "        video_display = Video(video_path, width=512, height=512, embed=True)\n",
        "\n",
        "        # Clear the output placeholder and display the video\n",
        "        with video_output_placeholder:\n",
        "            clear_output()\n",
        "            display(video_display)\n",
        "\n",
        "## Refresh folder and directory\n",
        "def refresh_folder_and_directory(change):\n",
        "    video_dir_folders = os.listdir(VIDEO_DIR_PATH)\n",
        "    video_dir_folder_content = getFolderContent(video_dir_folders)\n",
        "\n",
        "    video_dropdown.options = []\n",
        "    video_dropdown.value = None\n",
        "\n",
        "    video_subdir_dropdown.options = video_dir_folder_content\n",
        "    video_subdir_dropdown.value = None\n",
        "\n",
        "\n",
        "\n",
        "## Enable button when a valid video is picked\n",
        "def enable_button(change):\n",
        "    if video_dropdown.value:\n",
        "        video_display_button.disabled = False\n",
        "        video_mmpose_button.disabled = False\n",
        "        video_fyp_button.disabled = False\n",
        "    else:\n",
        "        video_display_button.disabled = True\n",
        "        video_mmpose_button.disabled = True\n",
        "        video_fyp_button.disabled = True\n",
        "\n",
        "# Attach Listeners\n",
        "video_subdir_dropdown.observe(video_subdir_select, 'value')\n",
        "video_display_button.on_click(display_selected_video)\n",
        "video_refresh_button.on_click(refresh_folder_and_directory)\n",
        "video_dropdown.observe(enable_button, 'value')\n",
        "\n",
        "\n",
        "# Display fields\n",
        "with video_output_placeholder:\n",
        "  display(video_output_placeholder_content)\n",
        "display(video_output_placeholder)\n",
        "display(video_subdir_dropdown)\n",
        "display(video_dropdown)\n",
        "\n",
        "display(video_hbox_1)\n",
        "display(video_hbox_2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHkYsaGTXcNs"
      },
      "source": [
        "## Inference: MMPOSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_1pswCixoU9"
      },
      "outputs": [],
      "source": [
        "# @title Run MMPose Inference { display-mode: \"form\" }\n",
        "\n",
        "# Helper Functions\n",
        "## Re-encode video due to H.264 video encoding error\n",
        "def reencode_video(input_file):\n",
        "  temp_output_file = f\"{VIDEO_SKELETON_DIR_PATH}/output.mp4\"\n",
        "  !ffmpeg -i {input_file} -c:v libx264 -crf 23 -c:a aac -strict experimental {temp_output_file}\n",
        "\n",
        "  os.remove(input_file)\n",
        "  os.rename(temp_output_file, input_file)\n",
        "\n",
        "# Create layout\n",
        "layout_single_long_button = widgets.Layout(margin='0px 0px 20px 154px')\n",
        "\n",
        "# Create widgets\n",
        "selected_mmpose_video_input = widgets.Text(placeholder='Select a video above', description=\"Video:\", disabled=True)\n",
        "inf_mmpose_button = widgets.Button(description=\"Start Inference\", disabled=True, layout=layout_single_long_button)\n",
        "\n",
        "# Create listeners\n",
        "## Retrieve video input\n",
        "def update_mmpose_input_video(change):\n",
        "    selected_video = video_dropdown.value\n",
        "    selected_mmpose_video_input.value = selected_video\n",
        "    if selected_video:\n",
        "        inf_mmpose_button.disabled = False\n",
        "    else:\n",
        "        inf_mmpose_button.disabled = True\n",
        "\n",
        "## Run mmpose\n",
        "def run_mmpose_inference(button):\n",
        "    selected_video = video_dropdown.value\n",
        "    video_path = f\"/content/video/{video_subdir_dropdown.value}/{selected_video}\"\n",
        "\n",
        "    %cd -q {MMPOSE_DIR_PATH}\n",
        "\n",
        "    if not os.path.exists(VIDEO_SKELETON_DIR_PATH):\n",
        "        os.mkdir(VIDEO_SKELETON_DIR_PATH)\n",
        "\n",
        "    # Start inference\n",
        "    !python demo/inferencer_demo.py \\\n",
        "        {video_path}  \\\n",
        "        --pose2d human --vis-out-dir {VIDEO_SKELETON_DIR_PATH} \\\n",
        "        --black-background\n",
        "\n",
        "    input_file = f\"{VIDEO_SKELETON_DIR_PATH}/{selected_video}\"\n",
        "    reencode_video(input_file)\n",
        "\n",
        "    clear_output()\n",
        "    mmpose_inf_display()\n",
        "    print(f\"Done [Output: {input_file}]\")\n",
        "\n",
        "# Attach Listeners\n",
        "video_mmpose_button.on_click(update_mmpose_input_video)\n",
        "inf_mmpose_button.on_click(run_mmpose_inference)\n",
        "\n",
        "# Display fields\n",
        "def mmpose_inf_display():\n",
        "  display(selected_mmpose_video_input)\n",
        "  display(inf_mmpose_button)\n",
        "mmpose_inf_display()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naoA-L5VATod"
      },
      "source": [
        "## Inference: FYP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPncudQS7Uyn"
      },
      "outputs": [],
      "source": [
        "# @title Inference Configuration { display-mode: \"form\" }\n",
        "\n",
        "# Init\n",
        "%cd -q {FYP_DIR_PATH}\n",
        "\n",
        "# Initialize load_config with a default value\n",
        "load_config = None\n",
        "\n",
        "# Define a container for displayed widgets\n",
        "displayed_widgets = []\n",
        "\n",
        "# Get a list of all files in the directory\n",
        "config_files = [f for f in os.listdir(CONFIG_DIR_PATH) if os.path.isfile(os.path.join(CONFIG_DIR_PATH, f))]\n",
        "\n",
        "# Create a dropdown widget with the list of config files\n",
        "config_files_dropdown = Dropdown(\n",
        "  options=[\"- Select an Item -\"] + config_files,\n",
        "  description='Select a Config File:',\n",
        "  layout=Layout(width=\"500px\"),\n",
        "  style={'description_width': '150px'}\n",
        ")\n",
        "\n",
        "# Function to clear displayed widgets (excluding the dropdown)\n",
        "def clear_displayed_widgets():\n",
        "    for widget in displayed_widgets:\n",
        "        widget.close()\n",
        "    displayed_widgets.clear()\n",
        "    display(config_files_dropdown)  # Display the dropdown again\n",
        "\n",
        "# Function to update the load_config variable based on the selected filename\n",
        "def update_load_config(change):\n",
        "    global load_config\n",
        "    selected_filename = change.new\n",
        "    if selected_filename and selected_filename != \"- Select an Item -\":\n",
        "        clear_output(wait=True)  # Clear the output area\n",
        "        clear_displayed_widgets()  # Clear previously displayed widgets\n",
        "\n",
        "        # Load yaml file\n",
        "        sample_yaml_path = f\"{CONFIG_DIR_PATH}/{selected_filename}\"\n",
        "        load_config = OmegaConf.load(sample_yaml_path)\n",
        "        print(f\"Editing config from: {sample_yaml_path}\")\n",
        "\n",
        "        # Check if the yaml configuration matches expected training config\n",
        "        if compare_dict_structure(expected_inference_config, load_config):\n",
        "\n",
        "          # Create a list of model names and paths in the directory\n",
        "          model_options = create_model_list()\n",
        "\n",
        "          # =====================================\n",
        "          ## Basic Data\n",
        "          config_subheader1 = widgets.HTML(value=\"<h3>Basic Data</h3>\")\n",
        "          config_pretrained_model_path = Dropdown(options=model_options, description=\"pretrained_model_path:\", value=load_config.pretrained_model_path, style=configs_config_style, layout=configs_config_layout)\n",
        "          config_output_dir_name = widgets.Text(description=\"output_dir_name:\", value=\"\", style=configs_config_style, layout=configs_config_layout)\n",
        "          config_train_batch_size = widgets.IntText(description=\"train_batch_size:\", value=load_config.train_batch_size, style=configs_config_style, layout=configs_config_layout)\n",
        "          config_validation_steps = widgets.IntText(description=\"validation_steps:\", value=load_config.validation_steps, style=configs_config_style, layout=configs_config_layout)\n",
        "          config_seed = widgets.IntText(description=\"seed:\", value=load_config.seed, style=configs_config_style, layout=configs_config_layout)\n",
        "          config_mixed_precision = widgets.Text(description=\"mixed_precision:\", value=load_config.mixed_precision, style=configs_config_style, layout=configs_config_layout)\n",
        "          config_gradient_checkpointing = Dropdown(options=boolean_dropdown, value=load_config.gradient_checkpointing, description=\"gradient_checkpointing:\", style=configs_config_style, layout=configs_config_layout)\n",
        "          config_enable_xformers_memory_efficient_attention = Dropdown(options=boolean_dropdown, value=load_config.enable_xformers_memory_efficient_attention, description=\"enable_xformers_memory_efficient_attention:\", style=configs_config_style, layout=configs_config_layout)\n",
        "          # =====================================\n",
        "          ## Validation_data\n",
        "          config_subheader2 = widgets.HTML(value=\"<h3>Validation Data</h3>\")\n",
        "          config_prompts = widgets.Textarea(description=\"prompts:\", value=\"\\n\".join(load_config.validation_data.prompts), style=configs_config_style, layout=widgets.Layout(width=\"500px\", height=\"100px\"))\n",
        "          config_video_length = widgets.IntText(description=\"video_length:\", value=load_config.validation_data.video_length, style=configs_config_style, layout=configs_config_layout)\n",
        "          config_width = widgets.IntText(description=\"width:\", value=load_config.validation_data.width, style=configs_config_style, layout=configs_config_layout)\n",
        "          config_height = widgets.IntText(description=\"height:\", value=load_config.validation_data.height, style=configs_config_style, layout=configs_config_layout)\n",
        "          config_num_inference_steps = widgets.IntText(description=\"num_inference_steps:\", value=load_config.validation_data.num_inference_steps, style=configs_config_style, layout=configs_config_layout)\n",
        "          config_guidance_scale = widgets.FloatText(description=\"guidance_scale:\", value=load_config.validation_data.guidance_scale, style=configs_config_style, layout=configs_config_layout)\n",
        "          config_use_inv_latent = Dropdown(options=boolean_dropdown, value=load_config.validation_data.use_inv_latent, description=\"use_inv_latent:\", style=configs_config_style, layout=configs_config_layout)\n",
        "          config_num_inv_steps = widgets.IntText(description=\"num_inv_steps:\", value=load_config.validation_data.num_inv_steps, style=configs_config_style, layout=configs_config_layout)\n",
        "          # =====================================\n",
        "          ## Group widgets\n",
        "          config_vbox = widgets.VBox([\n",
        "              config_pretrained_model_path,\n",
        "              config_output_dir_name,\n",
        "              config_train_batch_size,\n",
        "              config_validation_steps,\n",
        "              config_seed,\n",
        "              config_mixed_precision,\n",
        "              config_gradient_checkpointing,\n",
        "              config_enable_xformers_memory_efficient_attention,\n",
        "          ])\n",
        "          config_vbox_validation_data = widgets.VBox([\n",
        "              config_prompts,\n",
        "              config_video_length,\n",
        "              config_width,\n",
        "              config_height,\n",
        "              config_num_inference_steps,\n",
        "              config_guidance_scale,\n",
        "              config_use_inv_latent,\n",
        "              config_num_inv_steps\n",
        "          ])\n",
        "\n",
        "          # Create listeners\n",
        "          def save_config(change):\n",
        "            config = {\n",
        "                \"pretrained_model_path\": config_pretrained_model_path.value,\n",
        "                \"output_dir\": f\"{INFERENCE_OUTPUT_DIR_PATH}/{config_output_dir_name.value}\",\n",
        "                \"validation_data\": {\n",
        "                    \"prompts\": [prompt.strip() for prompt in config_prompts.value.splitlines() if prompt.strip()],\n",
        "                    \"video_length\": config_video_length.value,\n",
        "                    \"width\": config_width.value,\n",
        "                    \"height\": config_height.value,\n",
        "                    \"num_inference_steps\": config_num_inference_steps.value,\n",
        "                    \"guidance_scale\": config_guidance_scale.value,\n",
        "                    \"use_inv_latent\": config_use_inv_latent.value,\n",
        "                    \"num_inv_steps\": config_num_inv_steps.value,\n",
        "                    \"dataset_set\": load_config.validation_data.dataset_set\n",
        "                },\n",
        "                \"train_batch_size\": config_train_batch_size.value,\n",
        "                \"validation_steps\": config_validation_steps.value,\n",
        "                \"resume_from_checkpoint\": load_config.resume_from_checkpoint,\n",
        "                \"seed\": config_seed.value,\n",
        "                \"mixed_precision\": config_mixed_precision.value,\n",
        "                \"gradient_checkpointing\": config_gradient_checkpointing.value,\n",
        "                \"enable_xformers_memory_efficient_attention\": config_enable_xformers_memory_efficient_attention.value\n",
        "            }\n",
        "\n",
        "            # Specify the folder path you want to check\n",
        "            folder_path = f'{INFERENCE_OUTPUT_DIR_PATH}/{config_output_dir_name.value}'\n",
        "\n",
        "            # Check if the folder exists\n",
        "            if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
        "              print(\"\\r\", f'There is already a folder with the name {config_output_dir_name.value}! Please rename your folder!', end=\"\")\n",
        "\n",
        "            else:\n",
        "              # Save updated config back into the yaml file\n",
        "              with open(sample_yaml_path, \"w\") as file:\n",
        "                yaml.dump(config, file, default_style='\"', default_flow_style=False, sort_keys=False)\n",
        "\n",
        "              print(\"\\r\", \"Saving...\", end=\"\")\n",
        "              time.sleep(2)\n",
        "              print(\"\\r\", \"Successfully saved!\", end=\"\")\n",
        "\n",
        "          ## Button Widget and Attach Listener\n",
        "          config_save_btn = widgets.Button(description=\"Save\", layout=configs_config_button_layout)\n",
        "          config_save_btn.on_click(save_config)\n",
        "\n",
        "          # Display fields (same as before)\n",
        "          display(\n",
        "            config_subheader1,\n",
        "            config_vbox,\n",
        "            config_subheader2,\n",
        "            config_vbox_validation_data,\n",
        "            config_save_btn\n",
        "          )\n",
        "\n",
        "          # Update the displayed_widgets list\n",
        "          displayed_widgets.extend([\n",
        "              config_subheader1,\n",
        "              config_vbox,\n",
        "              config_subheader2,\n",
        "              config_vbox_validation_data,\n",
        "              config_save_btn\n",
        "          ])\n",
        "\n",
        "        else:\n",
        "          print(\"The configuration for the yaml is not structured correctly for inference\")\n",
        "\n",
        "# Attach the event handler to the dropdown's 'value' trait\n",
        "config_files_dropdown.observe(update_load_config, names='value')\n",
        "\n",
        "# Display the dropdown widget and the output widget\n",
        "display(config_files_dropdown)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAFxAiNDNHfs"
      },
      "outputs": [],
      "source": [
        "# @title Run FYP Inference { display-mode: \"form\" }\n",
        "\n",
        "# Create layout\n",
        "layout_single_long_button = widgets.Layout(margin='0px 0px 20px 154px')\n",
        "\n",
        "# Create widgets\n",
        "selected_fyp_video_input = widgets.Text(placeholder='Select a video above', description=\"Video:\", disabled=True)\n",
        "config_file_path = widgets.Text(value='configs/pose_sample.yaml',description=\"Config File:\")\n",
        "inf_fyp_button = widgets.Button(description=\"Start Inference\", disabled=True, layout=layout_single_long_button)\n",
        "\n",
        "# Create listeners\n",
        "## Retrieve video input\n",
        "def update_fyp_input_video(change):\n",
        "    selected_video = video_dropdown.value\n",
        "    selected_fyp_video_input.value = f\"{VIDEO_DIR_PATH}/{video_subdir_dropdown.value}/{selected_video}\"\n",
        "    if selected_video:\n",
        "        inf_fyp_button.disabled = False\n",
        "    else:\n",
        "        inf_fyp_button.disabled = True\n",
        "\n",
        "## Run FYP\n",
        "def run_fyp_inference(button):\n",
        "    %cd -q {FYP_DIR_PATH}\n",
        "\n",
        "    config_file_path_text = config_file_path.value\n",
        "    video_file_path_text = selected_fyp_video_input.value\n",
        "\n",
        "    # Specify the folder path you want to check\n",
        "    load_config = OmegaConf.load(config_file_path_text)\n",
        "    folder_path = load_config.output_dir\n",
        "\n",
        "    # Check if the folder exists\n",
        "    if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
        "      print(\"\\r\", f'The folder path {load_config.output_dir}! Please rename your folder!', end=\"\")\n",
        "\n",
        "    else:\n",
        "      print(\"\\r\", \"\", end=\"\")\n",
        "      # Start inference\n",
        "      !TORCH_DISTRIBUTED_DEBUG=DETAIL accelerate launch txt2video.py \\\n",
        "          --config={config_file_path_text}  \\\n",
        "          --skeleton_path={video_file_path_text}\n",
        "\n",
        "## Pass on skeleton path\n",
        "def get_skeleton_path():\n",
        "    skeleton_path = selected_fyp_video_input.value\n",
        "    return skeleton_path\n",
        "\n",
        "## Pass on config path\n",
        "def get_config_path():\n",
        "    config_path = config_file_path.value\n",
        "    return config_path\n",
        "\n",
        "# Attach Listeners\n",
        "inf_fyp_button.on_click(run_fyp_inference)\n",
        "video_fyp_button.on_click(update_fyp_input_video)\n",
        "\n",
        "# Display fields\n",
        "display(selected_fyp_video_input)\n",
        "display(config_file_path)\n",
        "display(inf_fyp_button)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fhpx7NDPi-Hq"
      },
      "outputs": [],
      "source": [
        "#@title Post-Process Inference\n",
        "\n",
        "# Load the inference config file\n",
        "sample_yaml_path = f\"{CONFIG_DIR_PATH}/pose_sample.yaml\"\n",
        "load_config = OmegaConf.load(sample_yaml_path)\n",
        "\n",
        "# Creates the skeleton pose gif with the duration matching the sample gifs\n",
        "postprocess_mmpose(selected_fyp_video_input.value, load_config.validation_data.video_length, load_config.output_dir)\n",
        "\n",
        "# For every prompt, combine the sample gif with the pose gif and the prompt below\n",
        "for prompt in load_config.validation_data.prompts:\n",
        "  postprocess_gif(load_config.output_dir, prompt, load_config.validation_data.width)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Gif Display\n",
        "def getInferenceRunFolderContent(folder_name):\n",
        "  runfolders = []\n",
        "  for content in os.listdir(INFERENCE_OUTPUT_DIR_PATH):\n",
        "        content_path = os.path.join(INFERENCE_OUTPUT_DIR_PATH, content)\n",
        "\n",
        "        # Check if it's a directory and not hidden\n",
        "        if os.path.isdir(content_path) and not content.startswith(\".\"):\n",
        "            runfolders.append(content)\n",
        "\n",
        "  return runfolders\n",
        "\n",
        "# Init\n",
        "inference_run_folders = os.listdir(INFERENCE_OUTPUT_DIR_PATH)\n",
        "inference_run_folder_content = getFolderContent(inference_run_folders)\n",
        "\n",
        "# Create widgets\n",
        "gif_output_placeholder = widgets.Output(layout=layout_output)\n",
        "gif_subdir_dropdown = widgets.Dropdown(options=inference_run_folder_content, description='Folder:', value=None, disabled=False)\n",
        "gif_dropdown = widgets.Dropdown(options=[], description='Gif:', disabled=True)\n",
        "gif_display_button = widgets.Button(description=\"Display\", disabled=True, layout=layout_double_button)\n",
        "gif_refresh_button = widgets.Button(description=\"Refresh\", disabled=False, layout=layout_double_button)\n",
        "\n",
        "gif_hbox_1 = widgets.HBox([gif_display_button, gif_refresh_button], layout=layout_hbox)\n",
        "\n",
        "# Create listeners\n",
        "## Update gif dropdown options based on the selected folder\n",
        "def gif_subdir_select(change):\n",
        "    selected_gif_folder = gif_subdir_dropdown.value\n",
        "\n",
        "    if selected_gif_folder != None:\n",
        "      selected_GIF_DIR_PATH = f\"{INFERENCE_OUTPUT_DIR_PATH}/{selected_gif_folder}/processed\"\n",
        "      selected_gif_dir_content = [file for file in os.listdir(selected_GIF_DIR_PATH) if file.endswith('.gif')]\n",
        "    else:\n",
        "      selected_gif_dir_content = []\n",
        "\n",
        "    gif_dropdown.options = selected_gif_dir_content\n",
        "    if not selected_gif_dir_content:\n",
        "        gif_dropdown.disabled = False\n",
        "        gif_dropdown.value = None\n",
        "    else:\n",
        "        gif_dropdown.disabled = False\n",
        "\n",
        "## Display the selected gif\n",
        "def display_selected_gif(change):\n",
        "    selected_gif = gif_dropdown.value\n",
        "    selected_gif_folder = gif_subdir_dropdown.value\n",
        "\n",
        "    if selected_gif:\n",
        "        gif_path = f\"{INFERENCE_OUTPUT_DIR_PATH}/{selected_gif_folder}/{selected_gif}\"\n",
        "        gif_display = Image(filename=gif_path, width=512, height=512, embed=True)\n",
        "\n",
        "        # Clear the output placeholder and display the gif\n",
        "        with gif_output_placeholder:\n",
        "            clear_output()\n",
        "            display(gif_display)\n",
        "\n",
        "## Refresh folder and directory\n",
        "def refresh_folder_and_directory(change):\n",
        "    inference_run_folders = os.listdir(INFERENCE_OUTPUT_DIR_PATH)\n",
        "    inference_run_folder_content = getFolderContent(inference_run_folders)\n",
        "\n",
        "    gif_dropdown.options = []\n",
        "    gif_dropdown.value = None\n",
        "\n",
        "    gif_subdir_dropdown.options = inference_run_folder_content\n",
        "    gif_subdir_dropdown.value = None\n",
        "\n",
        "\n",
        "\n",
        "## Enable button when a valid gif is picked\n",
        "def enable_button(change):\n",
        "    if gif_dropdown.value:\n",
        "        gif_display_button.disabled = False\n",
        "    else:\n",
        "        gif_display_button.disabled = True\n",
        "\n",
        "# Attach Listeners\n",
        "gif_subdir_dropdown.observe(gif_subdir_select, 'value')\n",
        "gif_display_button.on_click(display_selected_gif)\n",
        "gif_refresh_button.on_click(refresh_folder_and_directory)\n",
        "gif_dropdown.observe(enable_button, 'value')\n",
        "\n",
        "\n",
        "# Display fields\n",
        "display(gif_output_placeholder)\n",
        "display(gif_subdir_dropdown)\n",
        "display(gif_dropdown)\n",
        "\n",
        "display(gif_hbox_1)"
      ],
      "metadata": {
        "id": "RQvzyi1dZmFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFRHv5DxoaJQ"
      },
      "source": [
        "## Training (WIP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Dx3MheZUWM0"
      },
      "outputs": [],
      "source": [
        "# @title Init { display-mode: \"form\" }\n",
        "\n",
        "# Charades Data Class from csv\n",
        "class CharadesData:\n",
        "  def __init__(self, row):\n",
        "    id, subject, scene, quality, relevance, verified, script, objects, descriptions, actions, length = row\n",
        "    self.id = id\n",
        "    self.subject = subject\n",
        "    self.scene = scene\n",
        "    self.quality = quality\n",
        "    self.relevance = relevance\n",
        "    self.verified = verified\n",
        "    self.script = script\n",
        "    self.objects = objects.split(\";\")\n",
        "    self.descriptions = descriptions\n",
        "    self.length = length\n",
        "    self.actions = {}\n",
        "\n",
        "    # Convert actions in proper data structure (\"class_id time_start time_end\" -> class_id: [time_start, time_end])\n",
        "    if len(actions) != 0:\n",
        "      action_substrings = actions.split(';')\n",
        "      for substring in action_substrings:\n",
        "        parts = substring.split()\n",
        "        key = parts[0]\n",
        "        values = [self.convert_to_ms(parts[1]), self.convert_to_ms(parts[2])]\n",
        "        self.actions[key] = values\n",
        "\n",
        "  # For printing\n",
        "  def __str__(self):\n",
        "        return f\"ID: {self.id}, Subject: {self.subject}, Scene: {self.scene}, Quality: {self.quality}, Relevance: {self.relevance}, Verified: {self.verified}, Script: {self.script}, Objects: {self.objects}, Descriptions: {self.descriptions}, Actions: {self.actions}, Length: {self.length}\"\n",
        "\n",
        "  # Helper function to convert time into ms\n",
        "  def convert_to_ms(self, seconds):\n",
        "    ss,ms = seconds.split('.')\n",
        "    total_ms = 1000*int(ss) + int(ms)\n",
        "    return total_ms\n",
        "\n",
        "  # Caption getter with template\n",
        "  def getCaption(self, index):\n",
        "    return f\"In a {self.scene} setting, within the context of '{self.script}', the action '{action_descriptions[list(self.actions.keys())[index]]}' is taking place.\"\n",
        "\n",
        "\n",
        "action_descriptions = {}\n",
        "charades_all = []\n",
        "\n",
        "# Load classes lookup table\n",
        "with open('/content/charades_lookup/Charades_v1_classes.txt', 'r') as file:\n",
        "    for line in file:\n",
        "        code, description = line.strip().split(' ', 1)\n",
        "        action_descriptions[code] = description\n",
        "\n",
        "# Load charades data A\n",
        "with open('/content/charades_lookup/Charades_v1_train.csv', mode='r') as file:\n",
        "    csv_reader = csv.reader(file)\n",
        "    next(csv_reader, None)\n",
        "\n",
        "    for row in csv_reader:\n",
        "        charadeData = CharadesData(row)\n",
        "        charades_all.append(charadeData)\n",
        "\n",
        "# Load charades data B\n",
        "with open('/content/charades_lookup/Charades_v1_test.csv', mode='r') as file:\n",
        "    csv_reader = csv.reader(file)\n",
        "    next(csv_reader, None)\n",
        "\n",
        "    for row in csv_reader:\n",
        "        charadeData = CharadesData(row)\n",
        "        charades_all.append(charadeData)\n",
        "\n",
        "clear_output()\n",
        "print(\"Data load successful!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUJI5iBUf7Ym"
      },
      "outputs": [],
      "source": [
        "# @title Dataset Preload (Video) { display-mode: \"form\" }\n",
        "\n",
        "# Init\n",
        "dataset_dir_folders = os.listdir(VIDEO_DIR_PATH)\n",
        "\n",
        "## Training env\n",
        "training_dataset = None\n",
        "training_idx = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "training_branch = f\"{TRAINING_CONTENT_DIR_PATH}/{training_idx}\"\n",
        "\n",
        "# Create layout\n",
        "config_style = {'description_width': '100px'}\n",
        "config_layout = widgets.Layout(width=\"300px\")\n",
        "config_button_layout = widgets.Layout(margin='0px 0px 20px 154px')\n",
        "\n",
        "# Create widgets\n",
        "dataset_folder_dropdown = widgets.Dropdown(options=[dir for dir in dataset_dir_folders if not dir.startswith(\".\")], description='Dataset Folder:', value=None, layout=config_layout, style=config_style)\n",
        "dataset_cutting_button = widgets.Button(description=\"Start Cutting\", disabled=True, layout=config_button_layout)\n",
        "\n",
        "# Create listeners\n",
        "def dataset_dir_select(change):\n",
        "  if dataset_folder_dropdown:\n",
        "    dataset_folder_content = os.listdir(f\"{VIDEO_DIR_PATH}/{dataset_folder_dropdown.value}\")\n",
        "    total_dataset_videos = len([file for file in dataset_folder_content if file.endswith('.mp4')])\n",
        "\n",
        "    dataset_cutting_button.disabled = False\n",
        "    dataset_cutting_button.description = f\"Start Cutting ({total_dataset_videos})\"\n",
        "\n",
        "def video_cutting_select(change):\n",
        "  os.makedirs(training_branch, exist_ok=True)\n",
        "  training_dataset = f\"{VIDEO_DIR_PATH}/{dataset_folder_dropdown.value}\"\n",
        "\n",
        "  # Loop video files from selected dataset folder\n",
        "  for video_file in os.listdir(training_dataset):\n",
        "    video, ext = os.path.splitext(video_file)\n",
        "\n",
        "    # Ignore non video files (Eg: .ipynb_checkpoint and csv)\n",
        "    if ext != \".mp4\":\n",
        "      continue\n",
        "\n",
        "    video_folder = f\"{training_branch}/{video}\"\n",
        "    if not os.path.exists(video_folder):\n",
        "      os.mkdir(video_folder)\n",
        "\n",
        "      # Retrieve charade object by ID\n",
        "      charade_data = None\n",
        "      for charade in charades_all:\n",
        "        if charade.id == video:\n",
        "            charade_data = charade\n",
        "            break\n",
        "\n",
        "      # If no clipping required, keep whole video\n",
        "      if not charade_data.actions:\n",
        "        print(f\"No clipping needed\")\n",
        "      else:\n",
        "        print(f\"Clipping {video}\")\n",
        "        charade_actions = charade_data.actions.items()\n",
        "        total_charade_actions = len(charade_actions)\n",
        "        for i, (class_id, timings) in enumerate(charade_actions):\n",
        "\n",
        "          input_video = f\"{training_dataset}/{video_file}\"\n",
        "          output_video = f\"{video_folder}/{video}{i+1:02}{ext}\"\n",
        "\n",
        "          print(f\"#{i+1}/{total_charade_actions}: {timings[0]}ms to {timings[0]+timings[1]}ms [I:{input_video}] [O:{output_video}]\")\n",
        "          !ffmpeg -i {input_video} -ss {timings[0]}ms -t {timings[1]}ms -c:v libx264 -c:a aac {output_video} -loglevel quiet\n",
        "    else:\n",
        "      print(f\"Folder already exist for video_id: {video}. Skipping ...\")\n",
        "  print(\"Finished Clipping\")\n",
        "\n",
        "# Attach Listeners\n",
        "dataset_folder_dropdown.observe(dataset_dir_select, 'value')\n",
        "dataset_cutting_button.on_click(video_cutting_select)\n",
        "\n",
        "# Display fields\n",
        "display(dataset_folder_dropdown)\n",
        "display(dataset_cutting_button)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dff8K4IXmuOm"
      },
      "outputs": [],
      "source": [
        "# @title Dataset Preload (Metadata) { display-mode: \"form\" }\n",
        "\n",
        "training_metadata_file = f\"{training_branch}/metadata.tsv\"\n",
        "with open(training_metadata_file, 'w', newline='', encoding='utf-8') as tsvfile:\n",
        "  fieldnames = ['part_id', 'clip_id', 'caption']\n",
        "  writer = csv.DictWriter(tsvfile, fieldnames=fieldnames, delimiter='\\t')\n",
        "  writer.writeheader()\n",
        "\n",
        "  for part_id in os.listdir(training_branch):\n",
        "    folder_path = os.path.join(training_branch, part_id)\n",
        "\n",
        "    # Ignore non video files (Eg: .ipynb_checkpoint and csv)\n",
        "    if not os.path.isdir(folder_path) or part_id.startswith(\".\"):\n",
        "      continue\n",
        "\n",
        "    charade_data = None\n",
        "    for charade in charades_all:\n",
        "      if charade.id == part_id:\n",
        "          charade_data = charade\n",
        "          break\n",
        "\n",
        "    if not charade_data:\n",
        "      print(\"Missing charades data, skipping ...\")\n",
        "      continue\n",
        "\n",
        "    # Sort by video sub-id to maintain order\n",
        "    training_video_files = sorted(os.listdir(folder_path), key=lambda x: int(os.path.splitext(x)[0][-2:]))\n",
        "    for i, clip in enumerate(training_video_files):\n",
        "      caption = charade_data.getCaption(i)\n",
        "      writer.writerow({\n",
        "          'part_id': part_id,\n",
        "          'clip_id': clip,\n",
        "          'caption': caption\n",
        "      })\n",
        "print(f\"TSV created: {training_metadata_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXhTK71O1Rku"
      },
      "outputs": [],
      "source": [
        "# @title Training Configuration { display-mode: \"form\" }\n",
        "\n",
        "# Init\n",
        "%cd -q {FYP_DIR_PATH}\n",
        "\n",
        "# Initialize load_config with a default value\n",
        "load_config = None\n",
        "\n",
        "# Get a list of all files in the directory\n",
        "config_files = [f for f in os.listdir(CONFIG_DIR_PATH) if os.path.isfile(os.path.join(CONFIG_DIR_PATH, f))]\n",
        "\n",
        "# Define a container for displayed widgets\n",
        "displayed_widgets = []\n",
        "\n",
        "# Create a dropdown widget with the list of config files\n",
        "config_files_dropdown = Dropdown(\n",
        "  options=[\"- Select an Item -\"] + config_files,\n",
        "  description='Select a Config File:',\n",
        "  layout=Layout(width=\"500px\"),\n",
        "  style={'description_width': '150px'}\n",
        ")\n",
        "\n",
        "# Function to clear displayed widgets (excluding the dropdown)\n",
        "def clear_displayed_widgets():\n",
        "    for widget in displayed_widgets:\n",
        "        widget.close()\n",
        "    displayed_widgets.clear()\n",
        "    display(config_files_dropdown)  # Display the dropdown again\n",
        "\n",
        "# Function to update the load_config variable based on the selected filename\n",
        "def update_load_config(change):\n",
        "    global load_config\n",
        "    selected_filename = change.new\n",
        "    if selected_filename and selected_filename != \"- Select an Item -\":\n",
        "        clear_output(wait=True)  # Clear the output area\n",
        "        clear_displayed_widgets()  # Clear previously displayed widgets\n",
        "\n",
        "        # Load yaml file\n",
        "        sample_yaml_path = f\"{CONFIG_DIR_PATH}/{selected_filename}\"\n",
        "        # load_config = OmegaConf.load(sample_yaml_path)\n",
        "        with open(sample_yaml_path, 'r') as yaml_file:\n",
        "          load_config = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
        "        print(f\"Editing config from: {sample_yaml_path}\")\n",
        "\n",
        "        # Check if the yaml configuration matches expected training config\n",
        "        if compare_dict_structure(expected_training_config, load_config):\n",
        "\n",
        "          # Create a list of model names and paths in the directory\n",
        "          model_options = create_model_list()\n",
        "          video_options = create_video_path_list()\n",
        "          video_path_default = load_config[\"train_data\"][\"video_path\"]\n",
        "\n",
        "          if not (os.path.exists(video_path_default) and os.path.isdir(video_path_default)):\n",
        "            video_path_default = \"/content/training_content/\"\n",
        "          # =====================================\n",
        "          ## Basic Data\n",
        "          config_subheader1 = widgets.HTML(value=\"<h3>Basic Data</h3>\")\n",
        "          config_pretrained_model_path = Dropdown(options=model_options, description=\"pretrained_model_path:\", value=load_config[\"pretrained_model_path\"], style=configs_config_style, layout=configs_config_layout)\n",
        "          config_output_dir_name = widgets.Text(description=\"output_dir_name:\", value=\"\", style=configs_config_style, layout=configs_config_layout)\n",
        "          config_learning_rate = widgets.FloatText(description=\"learning_rate:\", value=load_config[\"learning_rate\"], style=configs_config_style, layout=configs_config_layout)\n",
        "          # =====================================\n",
        "          # train_data\n",
        "          config_subheader2 = widgets.HTML(value=\"<h3>Train Data</h3>\")\n",
        "          config_video_path = Dropdown(options=video_options, description=\"video_path:\", value=video_path_default, style=configs_config_style, layout=configs_config_layout)\n",
        "          config_n_sample_frames = widgets.IntText(description=\"n_sample_frames:\", value=load_config[\"train_data\"][\"n_sample_frames\"], style=configs_config_style, layout=configs_config_layout)\n",
        "          config_train_data_width = widgets.IntText(description=\"width:\", value=load_config[\"train_data\"][\"width\"], style=configs_config_style, layout=configs_config_layout)\n",
        "          config_sample_frame_rate = widgets.IntText(description=\"sample_frame_rate:\", value=load_config[\"train_data\"][\"sample_frame_rate\"], style=configs_config_style, layout=configs_config_layout)\n",
        "          # =====================================\n",
        "          config_train_batch_size = widgets.IntText(description=\"train_batch_size:\", value=load_config[\"train_batch_size\"], style=configs_config_style, layout=configs_config_layout)\n",
        "          config_max_train_steps = widgets.IntText(description=\"max_train_steps:\", value=load_config[\"max_train_steps\"], style=configs_config_style, layout=configs_config_layout)\n",
        "          config_seed = widgets.IntText(description=\"seed:\", value=load_config[\"seed\"], style=configs_config_style, layout=configs_config_layout)\n",
        "          config_mixed_precision = widgets.Text(description=\"mixed_precision:\", value=load_config[\"mixed_precision\"], style=configs_config_style, layout=configs_config_layout)\n",
        "          config_use_8bit_adam = Dropdown(options=boolean_dropdown, value=load_config[\"use_8bit_adam\"], description=\"config_use_8bit_adam:\", style=configs_config_style, layout=configs_config_layout)\n",
        "          config_gradient_checkpointing = Dropdown(options=boolean_dropdown, value=load_config[\"gradient_checkpointing\"], description=\"gradient_checkpointing:\", style=configs_config_style, layout=configs_config_layout)\n",
        "          config_enable_xformers_memory_efficient_attention = Dropdown(options=boolean_dropdown, value=load_config[\"enable_xformers_memory_efficient_attention\"], description=\"enable_xformers_memory_efficient_attention:\", style=configs_config_style, layout=configs_config_layout)\n",
        "          # =====================================\n",
        "          ## Button Widget\n",
        "          config_save_btn = widgets.Button(description=\"Save\", layout=configs_config_button_layout)\n",
        "          ## Group widgets\n",
        "          config_vbox = widgets.VBox([\n",
        "              config_pretrained_model_path,\n",
        "              config_output_dir_name,\n",
        "              config_learning_rate,\n",
        "              config_train_batch_size,\n",
        "              config_max_train_steps,\n",
        "              config_seed,\n",
        "              config_mixed_precision,\n",
        "              config_use_8bit_adam,\n",
        "              config_gradient_checkpointing,\n",
        "              config_enable_xformers_memory_efficient_attention\n",
        "          ])\n",
        "          config_vbox_train_data = widgets.VBox([\n",
        "              config_video_path,\n",
        "              config_n_sample_frames,\n",
        "              config_train_data_width,\n",
        "              config_sample_frame_rate,\n",
        "          ])\n",
        "\n",
        "          # Display fields (same as before)\n",
        "          display(\n",
        "            config_subheader1,\n",
        "            config_vbox,\n",
        "            config_subheader2,\n",
        "            config_vbox_train_data,\n",
        "            config_save_btn\n",
        "          )\n",
        "\n",
        "          # Create listeners\n",
        "          def save_config(change):\n",
        "            config = {\n",
        "                \"pretrained_model_path\": config_pretrained_model_path.value,\n",
        "                \"output_dir\": f\"{CUSTOM_MODEL_DIR_PATH}/{config_output_dir_name.value}\",\n",
        "                \"train_data\": {\n",
        "                    \"video_path\": config_video_path.value,\n",
        "                    \"n_sample_frames\": config_n_sample_frames.value,\n",
        "                    \"width\": config_train_data_width.value,\n",
        "                    \"sample_frame_rate\": config_sample_frame_rate.value\n",
        "                },\n",
        "                \"learning_rate\": config_learning_rate.value,\n",
        "                \"train_batch_size\": config_train_batch_size.value,\n",
        "                \"max_train_steps\": config_max_train_steps.value,\n",
        "                \"trainable_modules\": load_config[\"trainable_modules\"],\n",
        "                \"seed\": config_seed.value,\n",
        "                \"mixed_precision\": config_mixed_precision.value,\n",
        "                \"use_8bit_adam\": config_use_8bit_adam.value,\n",
        "                \"gradient_checkpointing\": config_gradient_checkpointing.value,\n",
        "                \"enable_xformers_memory_efficient_attention\": config_enable_xformers_memory_efficient_attention.value\n",
        "            }\n",
        "\n",
        "            if config_video_path.value == f\"{TRAINING_CONTENT_DIR_PATH}/\":\n",
        "              print(\"\\r\", \"Please choose a training folder!\", end=\"\")\n",
        "\n",
        "            else:\n",
        "              #Save updated config back into yaml file\n",
        "              with open(sample_yaml_path, \"w\") as file:\n",
        "                yaml.dump(config, file, default_style='\"', default_flow_style=False, sort_keys=False)\n",
        "\n",
        "              print(\"\\r\", \"Saving...\", end=\"\")\n",
        "              time.sleep(2)\n",
        "              print(\"\\r\", \"Successfully saved!\", end=\"\")\n",
        "\n",
        "          # Attach Listeners\n",
        "          config_save_btn.on_click(save_config)\n",
        "\n",
        "          # Update the displayed_widgets list\n",
        "          displayed_widgets.extend([\n",
        "              config_subheader1,\n",
        "              config_vbox,\n",
        "              config_subheader2,\n",
        "              config_vbox_train_data,\n",
        "              config_save_btn,\n",
        "          ])\n",
        "\n",
        "        else:\n",
        "          print(\"The configuration for the yaml is not structured correctly for training\")\n",
        "\n",
        "# Attach the event handler to the dropdown's 'value' trait\n",
        "config_files_dropdown.observe(update_load_config, names='value')\n",
        "\n",
        "# Display the dropdown widgets\n",
        "display(config_files_dropdown)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PW2DKILlW1Hp"
      },
      "outputs": [],
      "source": [
        "# @title Run Training { display-mode: \"form\" }\n",
        "\n",
        "%cd -q {FYP_DIR_PATH}\n",
        "\n",
        "output_label = widgets.Label(value=\"Output will appear here:\")\n",
        "display(output_label)\n",
        "\n",
        "def run_command_and_display_output(command):\n",
        "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True, shell=True)\n",
        "    for line in process.stdout:\n",
        "        output_label.value = line.strip()  # Update the label with the live output\n",
        "    process.wait()\n",
        "\n",
        "run_command_and_display_output('TORCH_DISTRIBUTED_DEBUG=DETAIL accelerate launch train_followyourpose.py --config=\"configs/pose_train.yaml\"')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "HpMOpVG_KhHb",
        "y12b9B4VLmqU",
        "VoIkpghCv-4a",
        "iamRWbAVylrD"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}